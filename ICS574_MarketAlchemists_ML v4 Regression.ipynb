{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Course: ICS 574\n",
        "# Prject: Alchemists Project - EDA\n",
        "- Date: May 1st 2024\n",
        "- Project Members\n",
        "    - AHMED DHAFER ALQARNI, ID: 201453160\n",
        "    - WALEED ABDULLAH ALFAIFI, ID: 201640920\n",
        "    - ALGHAMDI, BANDAR, ID: 202206560"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.ml.feature import StringIndexer, VectorAssembler\n",
        "from pyspark.ml.evaluation import RegressionEvaluator\n",
        "from pyspark.ml.regression import DecisionTreeRegressor\n",
        "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
        "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n",
        "import seaborn as sns\n",
        "import numpy as np\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "24/03/31 06:35:56 WARN Utils: Your hostname, Bandars-MacBook-Pro.local resolves to a loopback address: 127.0.0.1; using 192.168.100.154 instead (on interface en0)\n",
            "24/03/31 06:35:56 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
            "Setting default log level to \"WARN\".\n",
            "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
            "24/03/31 06:35:57 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
          ]
        }
      ],
      "source": [
        "# Create a Spark session\n",
        "spark = SparkSession.builder.appName(\"Decision Tree Classifier Example 3\").getOrCreate()\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/var/folders/8r/wc11r95d3lgcc57lr4h_9m0w0000gn/T/ipykernel_2316/4115176948.py:8: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  stocks_specific_df.rename(columns={'date': 'Date'}, inplace=True)\n",
            "/var/folders/8r/wc11r95d3lgcc57lr4h_9m0w0000gn/T/ipykernel_2316/4115176948.py:9: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  stocks_specific_df.rename(columns={'close': 'Stock_Price'}, inplace=True)\n",
            "/var/folders/8r/wc11r95d3lgcc57lr4h_9m0w0000gn/T/ipykernel_2316/4115176948.py:10: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  stocks_specific_df['Date'] = pd.to_datetime(stocks_specific_df['Date'])\n",
            "/var/folders/8r/wc11r95d3lgcc57lr4h_9m0w0000gn/T/ipykernel_2316/4115176948.py:11: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
            "  brent_df['Date'] = pd.to_datetime(brent_df['Date'])\n",
            "/var/folders/8r/wc11r95d3lgcc57lr4h_9m0w0000gn/T/ipykernel_2316/4115176948.py:15: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  stocks_specific_df.rename(columns={'sectoer': 'Sector'}, inplace=True)\n"
          ]
        }
      ],
      "source": [
        "# Load the datasets as pandas DataFrames\n",
        "stocks_df = pd.read_csv(\"./datasets/Tadawul_stcks.csv\")\n",
        "brent_df = pd.read_csv(\"./datasets/BrentOilPrices.csv\")\n",
        "gold_df = pd.read_csv(\"./datasets/Gold_Daily.csv\")\n",
        "\n",
        "# Preprocess the stock data\n",
        "stocks_specific_df = stocks_df[(stocks_df['sectoer'] == 'Energy') | (stocks_df['sectoer'] == 'Materials')]\n",
        "stocks_specific_df.rename(columns={'date': 'Date'}, inplace=True)\n",
        "stocks_specific_df.rename(columns={'close': 'Stock_Price'}, inplace=True)\n",
        "stocks_specific_df['Date'] = pd.to_datetime(stocks_specific_df['Date'])\n",
        "brent_df['Date'] = pd.to_datetime(brent_df['Date'])\n",
        "gold_df['Date'] = pd.to_datetime(gold_df['Date'])\n",
        "brent_df.rename(columns={'Price': 'Brent_Price'}, inplace=True)\n",
        "gold_df.rename(columns={'Price': 'Gold_Price'}, inplace=True)\n",
        "stocks_specific_df.rename(columns={'sectoer': 'Sector'}, inplace=True)\n",
        "stocks_specific_df = stocks_specific_df[['Date', 'name', 'Stock_Price', 'Sector', 'symbol']]\n",
        "brent_df = brent_df[['Date', 'Brent_Price']]\n",
        "gold_df = gold_df[['Date', 'Gold_Price']]\n",
        "stocks_specific_df.fillna(method='ffill', inplace=True)\n",
        "stocks_brent_df = pd.merge(stocks_specific_df, brent_df, on='Date', how='inner')\n",
        "stocks_brent_gold_df = pd.merge(stocks_brent_df, gold_df, on='Date', how='inner')\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create a Spark DataFrame\n",
        "stocks_brent_gold_df_spark = spark.createDataFrame(stocks_brent_gold_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create a VectorAssembler for the features\n",
        "assembler = VectorAssembler(inputCols=[\"Stock_Price\", \"Brent_Price\", \"Gold_Price\"], outputCol=\"features\")\n",
        "stocks_brent_gold_df_spark = assembler.transform(stocks_brent_gold_df_spark)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define the DecisionTreeRegressor\n",
        "dt = DecisionTreeRegressor(featuresCol=\"features\", labelCol=\"Stock_Price\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "# define the evaluator\n",
        "# note the metricName parameter is rmse, which stands for Root Mean Squared Error. This is the default metric for regression problems.\n",
        "# Other metrics include r2 (R squared) and mae (Mean Absolute Error)\n",
        "# see the documentation for more details: https://spark.apache.org/docs/latest/api/python/pyspark.ml.html#pyspark.ml.evaluation.RegressionEvaluator\n",
        "evaluator = RegressionEvaluator(labelCol=\"Stock_Price\", predictionCol=\"prediction\", metricName=\"rmse\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define the grid of hyperparameters\n",
        "# We will use a ParamGridBuilder to construct a grid of parameters to search over.\n",
        "# With 3 values for dt.maxDepth and 5 values for dt.maxBins, this grid will have 3 x 5 = 15 parameter settings for CrossValidator to choose from.\n",
        "# see the documentation for more details: https://spark.apache.org/docs/latest/api/python/pyspark.ml.html#pyspark.ml.tuning.ParamGridBuilder\n",
        "paramGrid = ParamGridBuilder() \\\n",
        "    .addGrid(dt.maxDepth, [2, 3, 4, 5, 6, 7, 8, 9, 10]) \\\n",
        "    .addGrid(dt.maxBins, [10, 20, 40, 80, 100]) \\\n",
        "    .build()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define the CrossValidator\n",
        "# We will use a CrossValidator to select the best model.\n",
        "# A CrossValidator requires an Estimator, a set of Estimator ParamMaps, and an Evaluator.\n",
        "# see the documentation for more details: https://spark.apache.org/docs/latest/api/python/pyspark.ml.html#pyspark.ml.tuning.CrossValidator\n",
        "cv = CrossValidator(estimator=dt, estimatorParamMaps=paramGrid, evaluator=evaluator, numFolds=5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                \r"
          ]
        }
      ],
      "source": [
        "# fit the cv model with the assembled data\n",
        "cvModel = cv.fit(stocks_brent_gold_df_spark)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average RMSE:  9.841781224229344\n"
          ]
        }
      ],
      "source": [
        "# get the average cross-validated RMSE\n",
        "# note the RMSE is the root of the average of the squares of the differences between the predicted and the actual values\n",
        "# see the documentation for more details: https://spark.apache.org/docs/latest/api/python/pyspark.ml.html#pyspark.ml.evaluation.RegressionEvaluator\n",
        "\n",
        "# the higher the RMSE, the worse the model\n",
        "# the lower the RMSE, the better the model\n",
        "# the RMSE is a measure of the quality of the model\n",
        "# the RMSE is in the same units as the target variable\n",
        "# the RMSE is always non-negative\n",
        "# the RMSE is scale-dependent\n",
        "# the RMSE is not a percentage\n",
        "# the RMSE can be used to compare different models\n",
        "# the RMSE can be used to compare different transformations of the same model\n",
        "# the RMSE can be used to compare different models on different datasets\n",
        "# the RMSE can be used to compare different models on the same dataset\n",
        "# the RMSE can be used to compare different models on the same dataset with different target variables\n",
        "# the RMSE can be used to compare different models on the same dataset with the same target variable\n",
        "# the RMSE can be used to compare different models on the same dataset with the same target variable and different features\n",
        "# the RMSE can be used to compare different models on the same dataset with the same target variable and the same features\n",
        "# the RMSE can be used to compare different models on the same dataset with the same target variable and the same features and different hyperparameters\n",
        "# the RMSE can be used to compare different models on the same dataset with the same target variable and the same features and the same hyperparameters\n",
        "# the RMSE value of 0 means the model is perfect\n",
        "# the RMSE value of 9 means the model is good?\n",
        "avg_rmse = np.mean(cvModel.avgMetrics)\n",
        "print(\"Average RMSE: \", avg_rmse)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{Param(parent='DecisionTreeRegressor_434d5017f14b', name='cacheNodeIds', doc='If false, the algorithm will pass trees to executors to match instances with nodes. If true, the algorithm will cache node IDs for each instance. Caching can speed up training of deeper trees. Users can set how often should the cache be checkpointed or disable it by setting checkpointInterval.'): False, Param(parent='DecisionTreeRegressor_434d5017f14b', name='checkpointInterval', doc='set checkpoint interval (>= 1) or disable checkpoint (-1). E.g. 10 means that the cache will get checkpointed every 10 iterations. Note: this setting will be ignored if the checkpoint directory is not set in the SparkContext.'): 10, Param(parent='DecisionTreeRegressor_434d5017f14b', name='featuresCol', doc='features column name.'): 'features', Param(parent='DecisionTreeRegressor_434d5017f14b', name='impurity', doc='Criterion used for information gain calculation (case-insensitive). Supported options: variance'): 'variance', Param(parent='DecisionTreeRegressor_434d5017f14b', name='labelCol', doc='label column name.'): 'Stock_Price', Param(parent='DecisionTreeRegressor_434d5017f14b', name='leafCol', doc='Leaf indices column name. Predicted leaf index of each instance in each tree by preorder.'): '', Param(parent='DecisionTreeRegressor_434d5017f14b', name='maxBins', doc='Max number of bins for discretizing continuous features.  Must be >=2 and >= number of categories for any categorical feature.'): 100, Param(parent='DecisionTreeRegressor_434d5017f14b', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes. Must be in range [0, 30].'): 7, Param(parent='DecisionTreeRegressor_434d5017f14b', name='maxMemoryInMB', doc='Maximum memory in MB allocated to histogram aggregation. If too small, then 1 node will be split per iteration, and its aggregates may exceed this size.'): 256, Param(parent='DecisionTreeRegressor_434d5017f14b', name='minInfoGain', doc='Minimum information gain for a split to be considered at a tree node.'): 0.0, Param(parent='DecisionTreeRegressor_434d5017f14b', name='minInstancesPerNode', doc='Minimum number of instances each child must have after split. If a split causes the left or right child to have fewer than minInstancesPerNode, the split will be discarded as invalid. Should be >= 1.'): 1, Param(parent='DecisionTreeRegressor_434d5017f14b', name='minWeightFractionPerNode', doc='Minimum fraction of the weighted sample count that each child must have after split. If a split causes the fraction of the total weight in the left or right child to be less than minWeightFractionPerNode, the split will be discarded as invalid. Should be in interval [0.0, 0.5).'): 0.0, Param(parent='DecisionTreeRegressor_434d5017f14b', name='predictionCol', doc='prediction column name.'): 'prediction', Param(parent='DecisionTreeRegressor_434d5017f14b', name='seed', doc='random seed.'): 485216468309312964}\n"
          ]
        }
      ],
      "source": [
        "# print all the parameters of the best model\n",
        "print(cvModel.bestModel.extractParamMap())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "15.915918017272668\n",
            "14.281627995004516\n",
            "13.344991087045804\n",
            "13.230093311265122\n",
            "13.152253749942513\n",
            "14.571579011179526\n",
            "11.60517856311905\n",
            "9.953710149096313\n",
            "8.736322743530852\n",
            "8.45405101145592\n",
            "14.204317004683372\n",
            "11.046878927104736\n",
            "8.774626088088315\n",
            "6.916011299131246\n",
            "6.573127580083129\n",
            "14.109634446054141\n",
            "10.858033054980577\n",
            "8.46427368210331\n",
            "6.342382854255309\n",
            "5.9738789918995545\n",
            "14.057219052059262\n",
            "10.819929795729022\n",
            "8.383647789105341\n",
            "6.155372826761932\n",
            "5.852099521952239\n",
            "13.985779346677958\n",
            "10.795701039963602\n",
            "8.368194133246872\n",
            "6.1516046333679\n",
            "5.781998302890603\n",
            "13.959294812630285\n",
            "10.750884171568286\n",
            "8.36139494754078\n",
            "6.225511646818347\n",
            "5.7968964043610764\n",
            "13.958351184427233\n",
            "10.747112771052723\n",
            "8.396109221578362\n",
            "6.321505019330617\n",
            "5.942038590825033\n",
            "13.955867639310995\n",
            "10.73575510870954\n",
            "8.40692276306232\n",
            "6.432773036711319\n",
            "6.029301763342873\n"
          ]
        }
      ],
      "source": [
        "# print the RMSE of all the models\n",
        "for rmse in cvModel.avgMetrics:\n",
        "    print(rmse)\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# define multi-class evaluator\n",
        "evaluator = MulticlassClassificationEvaluator(labelCol=\"indexedLabel\", predictionCol=\"prediction\", metricName=\"accuracy\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Train-test split\n",
        "splits = stocks_brent_gold_df_spark.randomSplit([0.8, 0.2])\n",
        "train = splits[0]\n",
        "test = splits[1]\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Train the model\n",
        "model = dt.fit(train)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Make predictions\n",
        "predictions = model.transform(test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Root Mean Squared Error (RMSE): 8.042969898488115\n"
          ]
        }
      ],
      "source": [
        "# Evaluate the model\n",
        "evaluator = RegressionEvaluator(labelCol=\"Stock_Price\", predictionCol=\"prediction\", metricName=\"rmse\")\n",
        "rmse = evaluator.evaluate(predictions)\n",
        "print(\"Root Mean Squared Error (RMSE):\", rmse)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "R2: 0.9460308155664667\n"
          ]
        }
      ],
      "source": [
        "# evaluate the model using accuracy\n",
        "evaluator = RegressionEvaluator(labelCol=\"Stock_Price\", predictionCol=\"prediction\", metricName=\"r2\")\n",
        "r2 = evaluator.evaluate(predictions)\n",
        "print(\"R2:\", r2)\n",
        "\n",
        "# An R-squared (R2) value of 0.946 indicates that approximately 94.6% of the variance in the stock price can be explained by the features (Brent_Price and Gold_Price) in your model.\n",
        "\n",
        "# Generally, an R2 value close to 1 indicates that the model is able to explain a large proportion of the variance in the data, which is considered good. However, it's important to interpret this value in the context of your specific problem and domain knowledge."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Save the model\n",
        "model.save(\"decision_tree_regressor_model 2\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-------------------+--------------------+-----------+------+------+-----------+----------+--------------------+------------------+\n",
            "|               Date|                name|Stock_Price|Sector|symbol|Brent_Price|Gold_Price|            features|        prediction|\n",
            "+-------------------+--------------------+-----------+------+------+-----------+----------+--------------------+------------------+\n",
            "|2020-03-05 00:00:00|Saudi Arabia Refi...|       34.9|Energy|  2030|      51.29|    1690.5| [34.9,51.29,1690.5]| 34.65715564486664|\n",
            "|2020-03-05 00:00:00|Saudi Arabian Oil...|       33.0|Energy|  2222|      51.29|    1690.5| [33.0,51.29,1690.5]| 34.65715564486664|\n",
            "|2020-03-05 00:00:00|Rabigh Refining a...|       14.8|Energy|  2380|      51.29|    1690.5| [14.8,51.29,1690.5]|15.163399172310012|\n",
            "|2020-03-05 00:00:00|National Shipping...|      31.15|Energy|  4030|      51.29|    1690.5|[31.15,51.29,1690.5]| 30.75689315068493|\n",
            "|2020-03-05 00:00:00|Aldrees Petroleum...|       60.1|Energy|  4200|      51.29|    1690.5| [60.1,51.29,1690.5]| 60.25984197730956|\n",
            "+-------------------+--------------------+-----------+------+------+-----------+----------+--------------------+------------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# predict the stock price for the next day\n",
        "predictions = model.transform(stocks_brent_gold_df_spark)\n",
        "predictions.show(5)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [],
      "source": [
        "# compare the predicted stock price with the actual stock price\n",
        "predictions.toPandas().to_csv(\"predictions.csv\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Stop the Spark session\n",
        "spark.stop()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
